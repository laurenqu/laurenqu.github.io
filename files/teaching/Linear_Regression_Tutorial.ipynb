{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5398eb6",
   "metadata": {},
   "source": [
    "# Linear Regression and Related Topics\n",
    "\n",
    "This notebook summarizes key concepts of linear regression along with illustrative Python examples. Later, a real-world example using the built-in Diabetes dataset is provided to demonstrate the application of linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b473051a",
   "metadata": {},
   "source": [
    "## 1.1 Best Linear Prediction and Ordinary Least Squares (OLS)\n",
    "\n",
    "**Core Content:**\n",
    "- The best linear prediction (BLP) parameter \\(\\beta\\) is defined to minimize the expected squared error.\n",
    "- This leads to the formula \\(\\beta = (E[XX'])^{-1}E[XY]\\).\n",
    "- The Ordinary Least Squares (OLS) estimator is given by \\(\\hat{\\beta}_n = (X'X)^{-1}X'Y\\), with consistency and asymptotic properties discussed.\n",
    "\n",
    "**Key Python Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = 100\n",
    "p = 3\n",
    "X = np.random.randn(n, p)\n",
    "Y = np.dot(X, np.array([2, -1, 0.5])) + np.random.randn(n)\n",
    "beta_hat = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "print(\"OLS Estimator:\", beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1607479f",
   "metadata": {},
   "source": [
    "## 1.2 Frisch-Waugh-Lowell Theorem\n",
    "\n",
    "**Core Content:**\n",
    "- When splitting covariates into a target variable and controls, the coefficient of the target variable can be computed by partialling out the controls from both the dependent variable and the target variable.\n",
    "\n",
    "**Key Python Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cfc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import OLS, add_constant\n",
    "import numpy as np\n",
    "n = 100\n",
    "D = np.random.randn(n)\n",
    "W = np.random.randn(n, 2)\n",
    "Y = D + W @ np.array([0.5, -0.3]) + np.random.randn(n)\n",
    "X = add_constant(np.column_stack([D, W]))\n",
    "model = OLS(Y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db044708",
   "metadata": {},
   "source": [
    "## 1.3 Omitted Variable Bias\n",
    "\n",
    "**Core Content:**\n",
    "- When a relevant variable (e.g., \\(W\\)) is omitted from the regression, the estimated coefficient of the included variable (\\(D\\)) will be biased due to correlation between \\(D\\) and the omitted variable.\n",
    "\n",
    "**Key Python Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.randn(n)\n",
    "Y = 2*D + 0.5*W + np.random.randn(n)\n",
    "X_omit = add_constant(D)\n",
    "model_omit = OLS(Y, X_omit).fit()\n",
    "print(model_omit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfbb39b",
   "metadata": {},
   "source": [
    "## 1.4 Conditional Expectation\n",
    "\n",
    "**Core Content:**\n",
    "- The conditional expectation \\(E[Y|X]\\) is the expected value of \\(Y\\) given \\(X\\).\n",
    "- Key properties include linearity and the law of iterated expectations.\n",
    "\n",
    "**Key Python Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc1bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vals = np.random.randn(n)\n",
    "Y_vals = 3 * X_vals + np.random.randn(n)\n",
    "conditional_mean = np.mean(Y_vals[X_vals > 0])\n",
    "print(\"Conditional Expectation for X > 0:\", conditional_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a1c02",
   "metadata": {},
   "source": [
    "## 1.5 Linear Regression Model\n",
    "\n",
    "**Core Content:**\n",
    "- In the linear regression model \\(Y = X'\\beta + \\epsilon\\), the assumption \\(E[\\epsilon|X] = 0\\) implies \\(E[Y|X] = X'\\beta\\).\n",
    "\n",
    "**Key Python Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X = np.random.randn(n, 2)\n",
    "Y = 3 + 2*X[:, 0] - X[:, 1] + np.random.randn(n)\n",
    "model = LinearRegression().fit(X, Y)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a380e61",
   "metadata": {},
   "source": [
    "## 1.6 Potential Outcomes Framework and Causal Parameters\n",
    "\n",
    "**Core Content:**\n",
    "- Introduces treatment effects like Average Treatment Effect (ATE) and Conditional Average Treatment Effect (CATE), which are estimated based on potential outcomes.\n",
    "\n",
    "**Key Python Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.random.binomial(1, 0.5, n)\n",
    "Y0 = 10 + np.random.randn(n)\n",
    "Y1 = 15 + np.random.randn(n)\n",
    "Y = D * Y1 + (1 - D) * Y0\n",
    "ATE = np.mean(Y[D == 1]) - np.mean(Y[D == 0])\n",
    "print(\"Estimated ATE:\", ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47283e83",
   "metadata": {},
   "source": [
    "## 1.7 Endogeneity and Instrumental Variables\n",
    "\n",
    "**Core Content:**\n",
    "- Endogeneity occurs when regressors are correlated with the error term. Instrumental Variables (IV) are used to address this issue.\n",
    "\n",
    "**Key Python Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ae0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "Z = np.random.randn(n)\n",
    "X_iv = 0.5 * Z + np.random.randn(n)\n",
    "Y_iv = 2 * X_iv + np.random.randn(n)\n",
    "iv_model = IV2SLS(Y_iv, X_iv, instrument=Z).fit()\n",
    "print(iv_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e433c",
   "metadata": {},
   "source": [
    "## 1.8 Challenges with Many Covariates\n",
    "\n",
    "**Core Content:**\n",
    "- With many covariates, issues like multicollinearity and overfitting can arise. OLS becomes unstable when predictors are highly correlated.\n",
    "\n",
    "**Key Python Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.random.randn(n)\n",
    "X2 = 0.9 * X1 + 0.1 * np.random.randn(n)\n",
    "Y_multi = 3 * X1 + 0.5 * X2 + np.random.randn(n)\n",
    "X_multicol = add_constant(np.column_stack([X1, X2]))\n",
    "model_multicol = OLS(Y_multi, X_multicol).fit()\n",
    "print(model_multicol.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b8387",
   "metadata": {},
   "source": [
    "## Real-World Example: Diabetes Dataset\n",
    "\n",
    "We use the built-in Diabetes dataset from scikit-learn to perform linear regression and assess which variables are predictive of disease progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41e4840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Test R^2 Score:\", model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Diabetes Progression Prediction\")\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
